---
layout: post
title: Machine Learning with Python
date: 2018-01-14
published: true
---

There are countless tutorials for machine learning, however, I couldn't find one which could take me through the steps of not just the code but also of the math behind it. So here it goes.

To begin with, it is important to understand the concept of machine learning. Machine learning is a field of artificial intelligence, focused on training algorithms to (1) decipher patterns within data and (2) make predictions based on these patterns.

Amazon uses machine learning to make recommendations based on your past browsing history, Gmail uses machine learning to classify emails as spam or not-spam, and banks use machine learning to detect fraudulent transactions.

In essence, machine learning is nothing but a combination of various algorithms, such as: <br>
i.    Linear Regression <br>
ii.   Logistic Regression <br>
iii.  Decision Trees <br>
iv.   K-Nearest Neighbors <br>
v.    K-Means Clustering, among others.

In this story, I will be talking about a few of these algorithms, including the logic behind each of them. The first project that we shall work on is a classification project, using a public dataset called Iris. This is a very popular dataset, widely used in data science for explaining and demonstrating concepts.

After installation of python (3.6) and a text editor (I use atom), the first step towards evaluating the dataset is importing the various libraries, all part of the SciPy platform. The best way to do this is by running the following script, by typing it in a text editor, saving the file in a xyz.**py** format, and then calling it in the terminal by a simple $ python xyz.py command.

'''
import sys
print('Python: {}'.format(sys.version))
import scipy
print('scipy: {}'.format(scipy.__version__))
import numpy
print('numpy: {}'.format(numpy.__version__))
import matplotlib
print('matplotlib: {}'.format(matplotlib.__version__))
import pandas
print('pandas: {}'.format(pandas.__version__))
import sklearn
print('sklearn: {}'.format(sklearn.__version__))
'''

To load data from the Iris dataset into terminal, the following code would work. This can be used for any data import from the web or from a local directory.

```
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
dataset = pandas.read_csv(url, names=names)
print(dataset)
```

In line 3 of above script, we are instructing python to read the csv file at given url, name the columns as per listed 'names', and then save the data as 'dataset'. In line 4, we are instructing python to print the dataset. Since the dataset is pretty big, terminal would not print the entire thing but would give the first 30 and last 30 rows, along with the size of the table in the end as [150 rows x 5 columns].

It is always a good idea to start the analysis with a summary of every dataset, and python makes it very easy with the following simple and self explanatory command:

```
print(dataset.describe())
```

This would give the following result which is very useful in understanding the dataset:

       sepal-length  sepal-width  petal-length  petal-width <br>
count    150.000000   150.000000    150.000000   150.000000 <br>
mean       5.843333     3.054000      3.758667     1.198667 <br>
std        0.828066     0.433594      1.764420     0.763161 <br>
min        4.300000     2.000000      1.000000     0.100000 <br>
25%        5.100000     2.800000      1.600000     0.300000 <br>
50%        5.800000     3.000000      4.350000     1.300000 <br>
75%        6.400000     3.300000      5.100000     1.800000 <br>
max        7.900000     4.400000      6.900000     2.500000 <br>
